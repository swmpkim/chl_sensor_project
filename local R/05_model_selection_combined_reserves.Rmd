---
title: "Model for all reserves combined"
date: "12/8/2021"
output: 
    html_document:
        code_folding: hide
        toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE)
```

# Setup  

```{r}
library(readxl)
library(dplyr)
library(tidyr)
library(ggplot2)
library(patchwork)
library(lmerTest)
library(MuMIn)

load(here::here("data", "subset_no_NA.RData"))

# original plot settings, for later
op <- par()

# options, for MuMIn operations
# will prevent fitting sub-models to different datasets (from help file)
options(na.action = "na.fail")
```

One manipulation of data frame so I can code this up and make a final decision on a transformation later: generate a column called `response` that will be used in the models. If we decide on a square-root transformation, response will be calculated as `sqrt(extracted)`. That's what I'll work with for now but it can be changed to `extracted^(1/3)` or something different, and we should still be able to generate all relevant outputs.  

```{r}
dat$response <- sqrt(dat$extracted)
```


# Modeling  

**SEE `MuMIn::dredge()` and `MuMIn::mod.sel()`**  

`dredge()` will check all possible subsets of the model you give it. Can force it to keep a given term with `fixed = `.  This can be a bad idea if it causes you to consider implausible models! The only variables included in this dataframe though are ones that we want to know if we could keep or drop. From playing with this function, in the top models (delta AICc < 5, even <10), the only terms that get dropped are various flavors of interaction. Reserve doesn't get dropped until WAY down the list. FDOM gets dropped maybe 10 down, at delAICc around 10. So it's not great.  

I think this will tell us we really can't do much unless we can account for reserve.  

Unless it also works on mixed models, in which case we might have a shot.  

Example code just below, but it won't run yet because the full model is fitted down below.  

```{r}
# test <- MuMIn::dredge(full_ols, fixed = "sensor_rfu")
# test
# or show only the top ones - under some delta threshold:
# subset(test, delta < 10)
#'Best' model
# summary(get.models(test, 1)[[1]])

# ADD IN R2 and ADJUSTED R2
# test2 <- MuMIn::dredge(full_ols, fixed = "sensor_rfu", extra = c("R^2", "adjR^2"))
# see help file for how to pull in others


# test3 <- dredge(full_lmm, fixed = "sensor_rfu")
# test3

# compare different models, including different types
# model.sel(full_ols, full_lmm, mod3, mod4, mod5)
```

AICc is generally lower for the ols fits than the lmm ones. Although to generalize, lmm ones are better, so that's worth looking at. Coefficients are similar between the top ols fits and the full lmm. The top lmm fit though EXCLUDED FDOM!!! Actually the top few from the lmm. So we'll need to see how well those do with predictions, and what the R2 values are (do LMMs produce R2?).  

I think this is underscoring that how FDOM affects things depends on the reserve..... so there's not a magical big relationship.  


## Model 1: Full Model, OLS  

Includes all interactions between sensor_rfu, turbidity, and FDOM. Hoping we can actually drop some of these.  

Reserve included as fixed effect.  

response ~ sensor_rfu + turb + fdom_qsu + sensor_rfu\*turb\*fdom_qsu + sensor_rfu\*turb + sensor_rfu\*fdom_qsu + turb*fdom_qsu + temp + month + reserve

Fit model:  

```{r}
full_ols <- lm(response ~ sensor_rfu + turb + fdom_qsu + sensor_rfu*turb*fdom_qsu + sensor_rfu*turb + sensor_rfu*fdom_qsu + turb*fdom_qsu + temp + month + reserve, data = dat)
```

***  

## Model 2: Full Model, LMM  

Includes all interactions between sensor_rfu, turbidity, and FDOM. Hoping we can actually drop some of these.  

Reserve included as random effect. This would be ideal if we have enough data to make the model run.   

Fit model:  

```{r, message = TRUE, warning = TRUE}
full_lmm <- lmer(response ~ sensor_rfu + turb + fdom_qsu + sensor_rfu*turb*fdom_qsu + sensor_rfu*turb + sensor_rfu*fdom_qsu + turb*fdom_qsu + temp + month + (1 | reserve), data = dat)

```

AIC for this is actually higher than for the ordinary least squares version (`r AIC(full_lmm)` vs. `r AIC(full_ols)`), and it's harder to grab all the diagnostics from LMMs. So I'll stop working with mixed models here and only use fixed effects.  

***  

# Model Selection  

## OLS  

### Model Selection Table  

for delta AICc < 5 from top model  

```{r}
sel <- dredge(full_ols, 
                  fixed = "sensor_rfu",
                  extra = c("R^2", "AdjR^2" = function(x) summary(x)$adj.r.squared))
    
subset(sel, delta < 5)
```

### Summary of top model  

```{r}
summary(get.models(sel, 1)[[1]])
```
 

## LMM  

### Model Selection Table  

for delta AICc < 5 from top model  

```{r}
sel2 <- dredge(full_lmm, 
                  fixed = "sensor_rfu",
                  extra = c("R^2", "AdjR^2" = function(x) summary(x)$adj.r.squared))
    
subset(sel2, delta < 5)
```

### Summary of top model  

```{r}
summary(get.models(sel2, 1)[[1]])
```