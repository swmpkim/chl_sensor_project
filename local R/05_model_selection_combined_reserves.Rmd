---
title: "Model for all reserves combined"
date: "original: 12/8/2021; latest update: `r Sys.Date()`"
output: 
    html_document:
        code_folding: hide
        toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE)
```

# Setup  

```{r}
library(readxl)
library(dplyr)
library(tidyr)
library(ggplot2)
library(patchwork)
library(lmerTest)
library(MuMIn)
library(boot)

load(here::here("data", "subset_no_NA.RData"))

# original plot settings, for later
op <- par()

# options, for MuMIn operations
# will prevent fitting sub-models to different datasets (from help file)
options(na.action = "na.fail")
```

`response` column to use in models. Originally was unsure what transformation would be and wanted to be flexible. We decided as a group that square-root is okay.  

This means model predictions need to be squared to provide a meaningful estimate of chlorophyll.  

```{r}
dat$response <- sqrt(dat$extracted)
```


# Modeling  

**SEE `MuMIn::dredge()` and `MuMIn::mod.sel()`**  

`dredge()` will check all possible subsets of the model you give it. Can force it to keep a given term with `fixed = `.  This can be a bad idea if it causes you to consider implausible models! The only variables included in this dataframe though are ones that we want to know if we could keep or drop. 

Example code just below, but it won't run yet because the full model is fitted down below.  

```{r}
# test <- MuMIn::dredge(full_ols, fixed = "sensor_rfu")
# test
# or show only the top ones - under some delta threshold:
# subset(test, delta < 10)
#'Best' model
# summary(get.models(test, 1)[[1]])

# ADD IN R2 and ADJUSTED R2
# test2 <- MuMIn::dredge(full_ols, fixed = "sensor_rfu", extra = c("R^2", "adjR^2"))
# see help file for how to pull in others


# test3 <- dredge(full_lmm, fixed = "sensor_rfu")
# test3

# compare different models, including different types
# model.sel(full_ols, full_lmm, mod3, mod4, mod5)
```

AICc is generally lower for the ols fits than the lmm ones. Although to generalize, lmm ones are better, so that's worth looking at. Coefficients are similar between the top ols fits and the full lmm. The top lmm fit though EXCLUDED FDOM!!! Actually the top few from the lmm. So we'll need to see how well those do with predictions, and what the R2 values are (do LMMs produce R2?).  

I think this is underscoring that how FDOM affects things depends on the reserve..... so there's not a magical big relationship.  


## Model 1: Full Model, OLS  

Includes all interactions between sensor_rfu, turbidity, and FDOM. Additionally, temp\*rfu and temp\*fdom. Hoping we can actually drop some of these.  

Reserve included as fixed effect.  

response ~ sensor_rfu + turb + fdom_qsu + sensor_rfu\*turb\*fdom_qsu + sensor_rfu\*turb + sensor_rfu\*fdom_qsu + turb\*fdom_qsu + temp + sensor_rfu\*temp + fdom_qsu\*temp + season + reserve

Fit model:  

```{r}
full_ols <- glm(response ~ sensor_rfu + turb + fdom_qsu + sensor_rfu*turb*fdom_qsu + sensor_rfu*turb + sensor_rfu*fdom_qsu + turb*fdom_qsu + temp + sensor_rfu*temp + fdom_qsu*temp + season + reserve, data = dat)
```

***  

## Model 2: Full Model, LMM  

Includes all interactions between sensor_rfu, turbidity, and FDOM. Hoping we can actually drop some of these.  

Reserve included as random effect. This would be ideal if we have enough data to make the model run.   

Fit model:  

```{r, message = TRUE, warning = TRUE}
full_lmm <- lmer(response ~ sensor_rfu + turb + fdom_qsu + sensor_rfu*turb*fdom_qsu + sensor_rfu*turb + sensor_rfu*fdom_qsu + turb*fdom_qsu + temp + sensor_rfu*temp + fdom_qsu*temp + season  + (1 | reserve), data = dat)

```


**Keep in mind predictions will need to be made with the `re.form = ~0` argument because "new" data won't necessarily be from a reserve in the dataset, and we need to know how that will perform.**  

AIC for this is actually higher than for the ordinary least squares version (`r AIC(full_lmm)` vs. `r AIC(full_ols)`), and it's harder to grab all the diagnostics from LMMs.   

***  

# Model Selection  

## OLS  

### Full model    

for delta AICc < 2 from top model  

```{r}
sel.ols <- dredge(full_ols, 
                  fixed = "sensor_rfu",
                  extra = c("R^2", "AdjR^2" = function(x) summary(x)$adj.r.squared))

top.ols <- subset(sel.ols, delta < 2) %>% 
    mutate(model = "top.ols")
```

FDOM is in here, as are many interactions, but the coefficients are SO small.  

Reserve and season are in all of the top ones, so we really can't just extrapolate.  

### OLS, no FDOM    

....if we drop FDOM and all its interactions, what do we get.  

```{r}
no_fdom_ols <- glm(response ~ sensor_rfu + turb + sensor_rfu*turb + temp + sensor_rfu*temp + season + reserve, data = dat)

no.fdom.ols <- model.sel(no_fdom_ols) %>% 
    mutate(model = "no.fdom.ols")
```


```{r}
# summary(get.models(sel, 1)[[1]])
```
 

## LMM  

### Full Model    

for delta AICc < 2 from top model  

```{r}
sel.lmm <- dredge(full_lmm, 
                  fixed = "sensor_rfu")
    
top.lmm <- subset(sel.lmm, delta < 2) %>% 
    mutate(model = "top.lmm")
```
  

```{r}
# summary(get.models(sel2, 1)[[1]])
```

### LMM, no FDOM  

```{r}
no_fdom_lmm <- lmer(response ~ sensor_rfu + turb + sensor_rfu*turb + temp + sensor_rfu*temp + season + (1|reserve), data = dat)

no.fdom.lmm <- model.sel(no_fdom_lmm) %>% 
    mutate(model = "no.fdom.lmm")
```

# Table of coefficients and diagnostics    

```{r}
all.sel <- bind_rows(top.ols, no.fdom.ols, top.lmm, no.fdom.lmm)
```

# Cross-validation and prediction error  

Using only THE top model for each of OLS and LMM, plus the no-FDOM models  

```{r}
ols.1 <- get.models(sel.ols, 1)[[1]]
# predict(ols.1, newdata = dat)

lmm.1 <- get.models(sel.lmm, 1)[[1]]

# regular old RMSE
ols.cv <- cv.glm(dat, ols.1, K = 5)
ols.cv$delta
```

Because the predictions are the square root of what we're actually interested in, and i want *prediction* accuracy.  

# Cost Function for sMdAPE  

```{r}
cost <- function(obs, expt){
    median(
        abs(
            100 * (obs^2-expt^2) / ((obs^2+expt^2)/2)
        )
    )
}
```

```{r}
ols.cv <- cv.glm(dat, ols.1, cost, K = 10)
ols.cv$delta

ols.cv.df <- data.frame(model.sel(ols.1))%>% 
    dplyr::select(1:df)
ols.cv.df$pred_test_error <- ols.cv$delta[1]
```

41% off! Yikes!  

Is no FDOM any better?  

```{r}
ols.nofdom.cv <- cv.glm(dat, no_fdom_ols, cost, K = 10)
ols.nofdom.cv$delta


ols.nofdomcv.df <- data.frame(model.sel(no_fdom_ols)) %>% 
    dplyr::select(1:df)
ols.nofdomcv.df$pred_test_error <- ols.nofdom.cv$delta[1]
```

About the same. (not worse, so that's.... something?)  

# Summary Table for main models  

```{r}
cv_test_errors <- bind_rows(ols.cv.df, ols.nofdomcv.df) %>% 
  select(-family)

test <- data.frame(all.sel) %>% 
    full_join(., cv_test_errors) %>% 
    dplyr::select(model, AICc, pred_test_error, everything()) %>% 
    select(-family, -delta, -weight) %>% 
  mutate(across(c(AICc, pred_test_error), ~round(., 2)))

test


#, by = c("X.Intercept.", "fdom_qsu", "reserve", "season", "sensor_rfu", "temp", "turb", "fdom_qsu.temp", "sensor_rfu.temp", "sensor_rfu.turb", "df", "family")
```


# Graphics  

```{r}
dat2 <- dat %>% 
    mutate(preds_ols = (predict(ols.1, newdata = dat))^2,
           preds_nofdom_ols = (predict(no_fdom_ols, newdata = dat))^2,
           preds_lmm = (predict(lmm.1, newdata = dat))^2,
           preds_nofdom_lmm = (predict(no_fdom_lmm, newdata = dat))^2) %>% 
    arrange(extracted) %>% 
    mutate(rownum = row_number())
```

```{r}
ggplot(dat2, aes(x = rownum)) +
    geom_point(aes(y = preds_ols, color = "OLS"), alpha = 0.4) +
    geom_point(aes(y = preds_nofdom_ols, color = "OLS, no FDOM"), alpha = 0.4) +
    geom_point(aes(y = preds_lmm, color = "LMM"), alpha = 0.4) +
    geom_point(aes(y = preds_nofdom_lmm, color = "LMM, no FDOM"), alpha = 0.4) +
    geom_point(aes(y = extracted, color = "Extracted"), size = 3, alpha = 0.6) +
    labs(title = "Chl predictions from various models",
         x = "row number in data (sorted from smallest to largest chl a",
         y = "ug/L, extracted or predicted",
         color = "model")
```

```{r}
ggplot(dat2, aes(x = rownum)) +
    geom_point(aes(y = preds_ols, shape = "OLS", color = reserve), alpha = 0.5) +
    geom_point(aes(y = preds_nofdom_ols, shape = "OLS, no FDOM", color = reserve), alpha = 0.5) +
    geom_point(aes(y = extracted, shape = "Extracted", color = reserve), size = 3, alpha = 0.6) +
    labs(title = "Chl predictions, OLS models only",
         x = "row number in data (sorted from smallest to largest chl a",
         y = "ug/L, extracted or predicted",
         color = "Reserve",
         shape = "Model")
```

```{r}
ggplot(dat2, aes(x = rownum)) +
    geom_point(aes(y = preds_lmm, shape = "LMM", color = reserve), alpha = 0.5) +
    geom_point(aes(y = preds_nofdom_lmm, shape = "LMM, no FDOM", color = reserve), alpha = 0.5) +
    geom_point(aes(y = extracted, shape = "Extracted", color = reserve), size = 3, alpha = 0.6) +
    labs(title = "Chl predictions, LMM models only",
         x = "row number in data (sorted from smallest to largest chl a",
         y = "ug/L, extracted or predicted",
         color = "Reserve",
         shape = "Model")
```